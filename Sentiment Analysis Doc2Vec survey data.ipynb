{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vilma\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random\n",
    "import random\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each line, it stores the list of words and its label\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    print(item_no)\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    #When training the model is better that in each epoch the sequence of sentences is randomized.\n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = {'survey_data/test2_neg.txt':'TEST_NEG', 'survey_data/test2_pos.txt':'TEST_POS', 'IMDB_data/train-neg.txt':'TRAIN_NEG', 'IMDB_data/train-pos.txt':'TRAIN_POS', 'IMDB_data/train-unsup.txt':'TRAIN_UNS'}\n",
    "\n",
    "sentences = LabeledLineSentence(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model: Building the Vocabulary Table\n",
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "for epoch in range(10):\n",
    "    model.train(sentences.sentences_perm(), total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7218390703201294),\n",
       " ('nice', 0.6715968251228333),\n",
       " ('decent', 0.6600950360298157),\n",
       " ('bad', 0.6057783961296082),\n",
       " ('excellent', 0.5706406831741333),\n",
       " ('fine', 0.5537208914756775),\n",
       " ('terrific', 0.5260274410247803),\n",
       " ('solid', 0.4898747205734253),\n",
       " ('ok', 0.4893348813056946),\n",
       " ('passable', 0.48271363973617554)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the model\n",
    "model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7575660347938538),\n",
       " ('awful', 0.6870864629745483),\n",
       " ('bad', 0.6592953205108643),\n",
       " ('horrendous', 0.6562106609344482),\n",
       " ('poor', 0.6472522020339966),\n",
       " ('atrocious', 0.6378101110458374),\n",
       " ('abysmal', 0.6051012277603149),\n",
       " ('dreadful', 0.5724244117736816),\n",
       " ('laughable', 0.5478890538215637),\n",
       " ('horrid', 0.5400127172470093)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('terrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.32900566e-01,   1.28046945e-01,   8.17108691e-01,\n",
       "        -1.28636205e+00,  -3.84286582e-01,  -1.72999933e-01,\n",
       "        -8.85443110e-03,  -2.78399229e-01,   8.16115141e-02,\n",
       "         2.15010598e-01,   1.33238006e+00,  -3.49347025e-01,\n",
       "        -3.23957533e-01,   6.87140822e-01,  -7.11193621e-01,\n",
       "        -1.46157312e+00,  -3.74920905e-01,  -1.07739776e-01,\n",
       "         2.67666042e-01,  -2.92389154e-01,   5.87848604e-01,\n",
       "        -4.88268673e-01,   3.62446487e-01,  -1.37731612e-01,\n",
       "        -2.38904700e-01,  -5.42249858e-01,  -2.63350487e-01,\n",
       "        -1.05008967e-01,  -5.50208986e-01,   1.36532769e-01,\n",
       "         6.91218317e-01,   6.64953232e-01,  -5.26533425e-01,\n",
       "         3.16222250e-01,  -6.38727784e-01,   2.78452002e-02,\n",
       "         5.57127059e-01,   1.26426172e+00,  -4.30101156e-01,\n",
       "         2.96567738e-01,  -1.18174350e+00,   1.73902422e-01,\n",
       "         1.20896352e-02,   8.58125329e-01,  -5.18964171e-01,\n",
       "         1.21728711e-01,  -5.90283096e-01,  -1.10897079e-01,\n",
       "        -9.23990458e-02,   6.20374799e-01,   1.99953169e-02,\n",
       "         2.91370392e-01,   3.69116315e-04,   1.87319100e-01,\n",
       "         1.87745064e-01,   2.28179574e-01,  -2.43826702e-01,\n",
       "         8.87627542e-01,  -3.00748795e-02,  -2.20251277e-01,\n",
       "        -3.55480343e-01,  -1.06641793e+00,  -1.21689463e+00,\n",
       "        -8.21248591e-01,   6.11146510e-01,   7.32248187e-01,\n",
       "         4.71668363e-01,  -9.76131260e-01,  -7.37920523e-01,\n",
       "        -4.99772519e-01,   3.12960416e-01,  -6.76200092e-01,\n",
       "         1.53641045e+00,  -7.60331154e-02,  -6.11344874e-01,\n",
       "         9.02803063e-01,   3.29468936e-01,  -3.02179158e-01,\n",
       "        -6.97448671e-01,   5.84723093e-02,  -3.03240538e-01,\n",
       "        -5.23265481e-01,   9.05932367e-01,  -4.06688064e-01,\n",
       "         2.78523743e-01,  -2.38206044e-01,  -7.76251078e-01,\n",
       "        -8.70743155e-01,   3.60324532e-01,   9.90503356e-02,\n",
       "        -9.25917387e-01,  -1.51981860e-01,   2.95359731e-01,\n",
       "         3.12589884e-01,   6.67195082e-01,  -6.48777068e-01,\n",
       "        -1.91594899e-01,  -5.72592676e-01,  -2.17183698e-02,\n",
       "         7.15982616e-01], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['TRAIN_NEG_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving and Loading Models\n",
    "model.save('./imdb2.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#And load it\n",
    "model = Doc2Vec.load('./imdb2.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifying Sentiments : use vectors to train a classifier\n",
    "\n",
    "#create 2 parallel numpy arrays.\n",
    "train_arrays = numpy.zeros((25000, 100)) #contains the vectors\n",
    "train_labels = numpy.zeros(25000) #contains the labels\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    train_arrays[i] = model.docvecs[prefix_train_pos]\n",
    "    train_arrays[12500 + i] = model.docvecs[prefix_train_neg]\n",
    "    train_labels[i] = 1\n",
    "    train_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68797094  0.76457405  0.32956964 ...,  0.15791994  0.28586188\n",
      "   0.31513771]\n",
      " [ 1.22653186 -0.33190563  0.78921872 ..., -0.44848043 -1.05658019\n",
      "   1.10037112]\n",
      " [-0.55923301 -1.30939567  0.12608586 ...,  0.4221797  -1.08332312\n",
      "   0.34219408]\n",
      " ..., \n",
      " [-0.60330433 -0.83032215  1.2487278  ...,  0.13907033  0.29023203\n",
      "  -0.64993906]\n",
      " [ 1.22132766 -0.1648977  -1.46663046 ..., -0.24398085 -1.69610143\n",
      "   1.56680501]\n",
      " [-0.20465086  0.29308414  0.39453363 ..., -0.35600445 -0.95190465\n",
      "   0.24759872]]\n"
     ]
    }
   ],
   "source": [
    "print(train_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing Vectors\n",
    "test_arrays = numpy.zeros((40, 100))\n",
    "test_labels = numpy.zeros(40)\n",
    "\n",
    "for i in range(20):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    test_arrays[i] = model.docvecs[prefix_test_pos]\n",
    "    test_arrays[20 + i] = model.docvecs[prefix_test_neg]\n",
    "    test_labels[i] = 1\n",
    "    test_labels[20 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arrays[2]\n",
    "test_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67500000000000004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "predict_labels = classifier.predict(test_arrays)\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  6]\n",
      " [ 7 13]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.70      0.68        20\n",
      "        1.0       0.68      0.65      0.67        20\n",
      "\n",
      "avg / total       0.68      0.68      0.67        40\n",
      "\n",
      "\n",
      "Accuracy:  0.675\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(test_labels, predict_labels))\n",
    "print()\n",
    "print( classification_report(test_labels, predict_labels))\n",
    "print()\n",
    "print (\"Accuracy: \", accuracy_score(test_labels, predict_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
